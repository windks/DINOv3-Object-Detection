#!/usr/bin/env python3
"""
DINOv3 Object Detection - ë¡œì»¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ì§ì ‘ ì‹¤í–‰ ê°€ëŠ¥í•œ ë…ë¦½í˜• í”„ë¡œê·¸ë¨

ì‚¬ìš©ë²•:
    python detect.py image.jpg "ì‚¬ëŒ" "ìë™ì°¨" "ê°•ì•„ì§€"
    python detect.py image.jpg --targets "ì‚¬ëŒ,ìë™ì°¨,ê°•ì•„ì§€" --output result.jpg
    python detect.py video.mp4 --targets "person,car" --output output.mp4
"""

import argparse
import cv2
import sys
import os
from pathlib import Path
from typing import List
import json

from production_api import DINOv3DetectorAPI, process_video


def parse_arguments():
    parser = argparse.ArgumentParser(
        description="DINOv3 Object Detection - ë¡œì»¬ ì‹¤í–‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  # ì´ë¯¸ì§€ì—ì„œ ê°ì²´ ì°¾ê¸°
  python detect.py photo.jpg "ì‚¬ëŒ" "ìë™ì°¨" "ê°•ì•„ì§€"
  
  # ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ íƒ€ê²Ÿ
  python detect.py photo.jpg --targets "person,car,dog"
  
  # ê²°ê³¼ ì €ì¥
  python detect.py photo.jpg --targets "ì‚¬ëŒ,ìë™ì°¨" --output detected.jpg
  
  # ë¹„ë””ì˜¤ ì²˜ë¦¬
  python detect.py video.mp4 --targets "person,car" --output result.mp4
  
  # ìƒì„¸ ì˜µì…˜
  python detect.py photo.jpg --targets "ë¹¨ê°„ ì°¨,íŒŒë€ ì°¨" --threshold 0.2 --model large
        """
    )
    
    parser.add_argument(
        "input",
        help="ì…ë ¥ ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ"
    )
    
    parser.add_argument(
        "targets",
        nargs="*",
        help="ì°¾ì„ ê°ì²´ë“¤ (ì˜ˆ: ì‚¬ëŒ ìë™ì°¨ ê°•ì•„ì§€)"
    )
    
    parser.add_argument(
        "--targets",
        "-t",
        dest="targets_comma",
        help="ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ì‚¬ëŒ,ìë™ì°¨,ê°•ì•„ì§€)"
    )
    
    parser.add_argument(
        "--output",
        "-o",
        help="ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ì´ë¯¸ì§€/ë¹„ë””ì˜¤)"
    )
    
    parser.add_argument(
        "--threshold",
        "-th",
        type=float,
        default=0.3,
        help="ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸: 0.3)"
    )
    
    parser.add_argument(
        "--model",
        "-m",
        choices=["small", "base", "large"],
        default="small",
        help="ëª¨ë¸ í¬ê¸° (ê¸°ë³¸: small)"
    )
    
    parser.add_argument(
        "--json",
        "-j",
        help="JSON ê²°ê³¼ ì €ì¥ ê²½ë¡œ"
    )
    
    parser.add_argument(
        "--no-display",
        action="store_true",
        help="ê²°ê³¼ í™”ë©´ì— í‘œì‹œ ì•ˆí•¨"
    )
    
    parser.add_argument(
        "--gpu",
        action="store_true",
        help="GPU ì‚¬ìš© (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)"
    )
    
    parser.add_argument(
        "--list",
        action="store_true",
        help="íƒì§€ëœ ê°ì²´ ëª©ë¡ë§Œ ì¶œë ¥"
    )
    
    return parser.parse_args()


def process_image(detector, image_path, targets, args):
    """ì´ë¯¸ì§€ ì²˜ë¦¬"""
    print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {image_path}")
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # íƒì§€
    print(f"ğŸ” ì°¾ëŠ” ê°ì²´: {targets}")
    results = detector.detect(
        image_rgb,
        targets,
        confidence_threshold=args.threshold
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š íƒì§€ ê²°ê³¼: {len(results)}ê°œ ê°ì²´ ë°œê²¬")
    if results:
        print("-" * 50)
        for i, det in enumerate(results, 1):
            print(f"{i}. {det.class_name}")
            print(f"   ì‹ ë¢°ë„: {det.confidence:.1%}")
            print(f"   ìœ„ì¹˜: {det.bbox}")
        print("-" * 50)
    
    # ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥ ëª¨ë“œ
    if args.list:
        detected_names = [det.class_name for det in results]
        print("\níƒì§€ëœ ê°ì²´:", ", ".join(detected_names))
    
    # JSON ì €ì¥
    if args.json:
        save_json(results, args.json, image_path)
    
    # ì‹œê°í™”
    if args.output or not args.no_display:
        vis_image = detector.visualize(image_rgb, results)
        
        if args.output:
            output_path = args.output if args.output.endswith(('.jpg', '.png')) else f"{args.output}.jpg"
            cv2.imwrite(output_path, cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR))
            print(f"âœ… ê²°ê³¼ ì €ì¥: {output_path}")
        
        if not args.no_display:
            # í™”ë©´ì— í‘œì‹œ
            cv2.imshow('Detection Result', cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR))
            print("\nì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()


def process_video_file(detector, video_path, targets, args):
    """ë¹„ë””ì˜¤ ì²˜ë¦¬"""
    print(f"\nğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘: {video_path}")
    
    if not args.output:
        output_path = video_path.stem + "_detected.mp4"
    else:
        output_path = args.output
    
    print(f"ğŸ” ì°¾ëŠ” ê°ì²´: {targets}")
    print(f"ğŸ“¹ ì¶œë ¥ ë¹„ë””ì˜¤: {output_path}")
    
    # ë¹„ë””ì˜¤ ì²˜ë¦¬
    process_video(
        str(video_path),
        str(output_path),
        targets,
        threshold=args.threshold
    )
    
    print(f"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {output_path}")


def save_json(results, json_path, source_path):
    """JSONìœ¼ë¡œ ê²°ê³¼ ì €ì¥"""
    data = {
        "source": str(source_path),
        "detections": [
            {
                "class_name": det.class_name,
                "confidence": float(det.confidence),
                "bbox": list(det.bbox)
            }
            for det in results
        ],
        "total": len(results)
    }
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ JSON ì €ì¥: {json_path}")


def main():
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    args = parse_arguments()
    
    # íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    targets = []
    if args.targets:
        targets.extend(args.targets)
    if args.targets_comma:
        targets.extend([t.strip() for t in args.targets_comma.split(",")])
    
    if not targets:
        print("âŒ ì˜¤ë¥˜: ì°¾ì„ ê°ì²´ë¥¼ ì§€ì •í•˜ì„¸ìš”!")
        print("ì˜ˆ: python detect.py image.jpg ì‚¬ëŒ ìë™ì°¨")
        print("ë˜ëŠ”: python detect.py image.jpg --targets ì‚¬ëŒ,ìë™ì°¨")
        sys.exit(1)
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        sys.exit(1)
    
    # ë””í…í„° ì´ˆê¸°í™”
    print(f"\nğŸš€ DINOv3 Object Detection ì‹œì‘")
    print(f"ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘... (model={args.model})")
    
    device = "cuda" if args.gpu else None
    detector = DINOv3DetectorAPI(
        model_size=args.model,
        device=device,
        use_fp16=args.gpu
    )
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    
    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
    if input_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        process_image(detector, input_path, targets, args)
        
    elif input_path.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv']:
        # ë¹„ë””ì˜¤ ì²˜ë¦¬
        process_video_file(detector, input_path, targets, args)
        
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {input_path.suffix}")
        sys.exit(1)
    
    print("\nâœ¨ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
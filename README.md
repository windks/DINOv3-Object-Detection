DINOv3 ç›®æ ‡æ£€æµ‹æ¡†æ¶ä½¿ç”¨é¢„è®­ç»ƒçš„ DINOv3 è§†è§‰ transformer è¿›è¡Œç”Ÿäº§å°±ç»ªçš„ç›®æ ‡æ£€æµ‹ã€‚æ— éœ€è®­ç»ƒ - ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°ç«‹å³æ£€æµ‹å¯¹è±¡ï¼ğŸ¯ æ— éœ€è®­ç»ƒï¼Œå³åˆ»ä½¿ç”¨ | ğŸ–±ï¸ GUI æ”¯æŒ | ğŸ–¥ï¸ æœ¬åœ°è¿è¡Œ | ğŸ Python APIğŸ“‹ ç›®å½•å®‰è£…æ–¹æ³•å¿«é€Ÿå…¥é—¨è¯¦ç»†ç”¨æ³•å®æˆ˜ç¤ºä¾‹æ€§èƒ½ä¼˜åŒ–ğŸš€ Key FeaturesZero-Shot Detection: ä½¿ç”¨æ–‡æœ¬æè¿°æ£€æµ‹ä»»ä½•å¯¹è±¡ - æ— éœ€è®­ç»ƒPretrained Models: ä½¿ç”¨ DINOv3 + CLIP è¿›è¡Œå³æ—¶ç›®æ ‡æ£€æµ‹Natural Language: æè¿°æ‚¨æƒ³æŸ¥æ‰¾çš„å†…å®¹ (ä¾‹å¦‚ï¼š"çº¢è‰²çš„è½¦", "æˆ´å¸½å­çš„äºº")Production Ready: ä¸“ä¸ºå®é™…åº”ç”¨è®¾è®¡çš„ç®€å• APIFast Inference: æ”¯æŒ FP16ï¼Œæ¨ç†é€Ÿåº¦ä¼˜åŒ–Flexible: é€‚ç”¨äºå›¾åƒå’Œè§†é¢‘ğŸ›  å®‰è£…æ–¹æ³•1. ä½¿ç”¨ UV (æ¨è)Bash# å…‹éš†ä»“åº“
git clone https://github.com/euisuk-chung/DINOv3-Object-Detection.git
cd Dino_v3_OD

# ä½¿ç”¨ UV å®‰è£…ä¾èµ–
uv sync
2. ä½¿ç”¨ pipBash# å…‹éš†ä»“åº“å
cd Dino_v3_OD

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (å¯é€‰)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install torch torchvision
pip install transformers opencv-python pillow numpy scipy
ğŸš€ å¿«é€Ÿå…¥é—¨ (5åˆ†é’Ÿä¸Šæ‰‹!)ğŸ–¥ï¸ æœ¬åœ°è¿è¡Œ (3ç§æ–¹å¼)æ–¹å¼ 1: ğŸ–±ï¸ è¿è¡Œ GUI (æ¨èæ–°æ‰‹)Bash# è¿è¡Œ GUI
python detect_gui.py

# Windows: åŒå‡»è¿è¡Œ
run_detector.bat
æ”¯æŒé¼ æ ‡æ“ä½œæ”¯æŒå›¾åƒé¢„è§ˆå®æ—¶æŸ¥çœ‹ç»“æœæ–¹å¼ 2: ğŸ’» å‘½ä»¤è¡Œ (CLI)Bash# å¤„ç†å•ä¸ªå›¾åƒ
python detect.py photo.jpg "äºº" "æ±½è½¦" "ç‹—"

# ä¿å­˜ç»“æœ
python detect.py photo.jpg --targets "person,car,dog" --output detected.jpg

# å¤„ç†è§†é¢‘
python detect.py video.mp4 --targets "äºº,æ±½è½¦" --output result.mp4

# é«˜çº§é€‰é¡¹
python detect.py image.jpg --targets "çº¢è‰²çš„è½¦" --threshold 0.2 --model large --gpu

# å¸®åŠ©
python detect.py --help
æ–¹å¼ 3: ğŸ“ æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹Bash# å¤„ç†æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰å›¾åƒ
python detect_folder.py ./images "äºº" "æ±½è½¦"

# å°†ç»“æœä¿å­˜ä¸º CSV
python detect_folder.py ./photos --targets "person,car,dog" --csv results.csv

# åŒ…å«å­æ–‡ä»¶å¤¹, å¹¶ä¿å­˜ç»“æœå›¾åƒ
python detect_folder.py ./dataset --targets "vehicle" --recursive --output ./results

# ä»…æŸ¥çœ‹æ‘˜è¦
python detect_folder.py ./images --targets "person" --summary
ğŸ Python ä»£ç è°ƒç”¨ - 3è¡Œæå®š!Pythonfrom production_api import detect_objects

# ä»å›¾åƒä¸­æŸ¥æ‰¾æ‰€éœ€å¯¹è±¡ - æ— éœ€è®­ç»ƒ!
results = detect_objects("photo.jpg", ["äºº", "æ±½è½¦", "ç‹—"])
print(f"æ‰¾åˆ°çš„å¯¹è±¡: {len(results)}ä¸ª")
ğŸ¯ ç¬¬ä¸€ä¸ªç¤ºä¾‹: ä»å›¾åƒä¸­æŸ¥æ‰¾å¯¹è±¡Pythonfrom production_api import DINOv3DetectorAPI
import cv2

# 1. åˆå§‹åŒ–æ£€æµ‹å™¨ (é¦–æ¬¡è¿è¡Œæ—¶ä¼šä¸‹è½½æ¨¡å‹)
detector = DINOv3DetectorAPI(model_size="small")  # ç”¨äºå¿«é€Ÿæµ‹è¯•

# 2. åŠ è½½å›¾åƒ
image = cv2.imread("my_photo.jpg")
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# 3. æŸ¥æ‰¾æ‰€éœ€å¯¹è±¡ - æ”¯æŒä¸­æ–‡!
results = detector.detect(
    image,
    ["äºº", "çº¢è‰²çš„è½¦", "é»„è‰²çš„å·´å£«", "ç‹—"],
    confidence_threshold=0.3  # ç½®ä¿¡åº¦é˜ˆå€¼
)

# 4. æ£€æŸ¥ç»“æœ
for detection in results:
    print(f"å‘ç°: {detection.class_name} (ç½®ä¿¡åº¦: {detection.confidence:.2f})")
    print(f"ä½ç½®: {detection.bbox}")

# 5. å¯è§†åŒ– (å¯é€‰)
vis_image = detector.visualize(image, results, "result.jpg")
ğŸ“– è¯¦ç»†ç”¨æ³•1ï¸âƒ£ åŸºæœ¬é…ç½®Pythonfrom production_api import DINOv3DetectorAPI

# é€‰æ‹©æ¨¡å‹å¤§å°
detector = DINOv3DetectorAPI(
    model_size="small",    # é€Ÿåº¦å¿«, é€‚åˆç®€å•å¯¹è±¡
    # model_size="base",     # æ€§èƒ½å‡è¡¡
    # model_size="large",    # å‡†ç¡®åº¦æœ€é«˜, é€Ÿåº¦æ…¢
    device="cuda",         # ä½¿ç”¨ GPU (å¦‚æœæ²¡æœ‰åˆ™ä¸º "cpu")
    use_fp16=True          # åœ¨ GPU ä¸Šæ¨ç†é€Ÿåº¦å¿« 2 å€
)
2ï¸âƒ£ å¤šç§è¾“å…¥æ–¹å¼Python# æ–¹å¼ 1: æ–‡ä»¶è·¯å¾„
results = detector.detect("image.jpg", ["person", "car"])

# æ–¹å¼ 2: numpy æ•°ç»„
import numpy as np
image_array = np.array(...)  # ä½ çš„å›¾åƒæ•°æ®
results = detector.detect(image_array, ["person", "car"])

# æ–¹å¼ 3: PIL å›¾åƒ
from PIL import Image
pil_image = Image.open("image.jpg")
image_array = np.array(pil_image)
results = detector.detect(image_array, ["person", "car"])
3ï¸âƒ£ ç”¨è‡ªç„¶è¯­è¨€æè¿°å¯¹è±¡Python# ç®€å•çš„å¯¹è±¡åç§°
simple_targets = ["äºº", "æ±½è½¦", "ç‹—", "çŒ«"]

# å…·ä½“çš„æè¿°
detailed_targets = [
    "çº¢è‰²çš„è·‘è½¦",
    "ç©¿è“è‰²è¡¬è¡«çš„äºº",
    "æˆ´çœ¼é•œçš„è€äºº",
    "èƒŒç€èƒŒåŒ…çš„å­¦ç”Ÿ",
    "é»„è‰²çš„æ ¡è½¦"
]

# å¤æ‚çš„åœºæ™¯
complex_targets = [
    "æ­£åœ¨è¿‡é©¬è·¯çš„äºº",
    "åœåœ¨çº¢ç¯å‰çš„è½¦",
    "å¼ç€çƒçš„ç‹—",
    "ä½¿ç”¨ç¬”è®°æœ¬ç”µè„‘çš„äºº"
]

results = detector.detect(image, detailed_targets)
4ï¸âƒ£ ç»“æœç­›é€‰Python# æ‰€æœ‰æ£€æµ‹ç»“æœ
all_results = detector.detect(image, targets, confidence_threshold=0.2)

# ä»…ä¿ç•™é«˜ç½®ä¿¡åº¦
high_confidence = detector.filter_detections(
    all_results,
    min_confidence=0.7
)

# ä»…ä¿ç•™ç‰¹å®šç±»åˆ«
only_people = detector.filter_detections(
    all_results,
    class_names=["äºº", "person"]
)

# ä»…ä¿ç•™å¤§å¯¹è±¡ (åŸºäºåƒç´ é¢ç§¯)
large_objects = detector.filter_detections(
    all_results,
    min_area=10000  # 100x100 åƒç´ ä»¥ä¸Š
)
5ï¸âƒ£ æ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒPython# å‡†å¤‡å›¾åƒåˆ—è¡¨
images = ["img1.jpg", "img2.jpg", "img3.jpg"]
targets = ["person", "car", "dog"]

# æ‰¹é‡å¤„ç†
all_results = detector.detect_batch(images, targets)

# æ¯ä¸ªå›¾åƒçš„ç»“æœ
for idx, results in enumerate(all_results):
    print(f"\nå›¾åƒ {idx+1}: å‘ç° {len(results)} ä¸ªå¯¹è±¡")
    for det in results:
        print(f"  - {det.class_name}: {det.confidence:.2f}")
6ï¸âƒ£ è§†é¢‘å¤„ç†Pythonfrom production_api import process_video

# ç®€å•çš„è§†é¢‘å¤„ç†
process_video(
    "input.mp4",        # è¾“å…¥è§†é¢‘
    "output.mp4",       # è¾“å‡ºè§†é¢‘
    ["äºº", "æ±½è½¦"],      # è¦æŸ¥æ‰¾çš„å¯¹è±¡
    threshold=0.3       # ç½®ä¿¡åº¦é˜ˆå€¼
)

# é«˜çº§è§†é¢‘å¤„ç† (æ‰‹åŠ¨æ§åˆ¶)
cap = cv2.VideoCapture("video.mp4")
while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # é€å¸§å¤„ç†
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = detector.detect(frame_rgb, ["person", "car"])
    
    # æ‰§è¡Œä½ æƒ³è¦çš„å¤„ç†...
ğŸ’¡ å®æˆ˜ç¤ºä¾‹ç¤ºä¾‹ 1: å®‰é˜²æ‘„åƒå¤´ç›‘æ§Python# æ£€æµ‹ç‰¹å®šæƒ…å†µ
security_targets = [
    "èƒŒç€èƒŒåŒ…çš„äºº",
    "è¢«é—å¼ƒçš„åŒ…",
    "å¥”è·‘çš„äºº",
    "å€’ä¸‹çš„äºº",
    "æˆ´å£ç½©çš„äºº"
]

results = detector.detect(cctv_frame, security_targets)

# å±é™©æƒ…å†µè­¦æŠ¥
for det in results:
    if det.class_name == "å€’ä¸‹çš„äºº" and det.confidence > 0.7:
        send_alert("æ£€æµ‹åˆ°ç´§æ€¥æƒ…å†µ!")
ç¤ºä¾‹ 2: åº“å­˜ç®¡ç†Python# æŸ¥æ‰¾äº§å“
products = [
    "å¯å£å¯ä¹ç½",
    "ç™¾äº‹å¯ä¹ç“¶",
    "æ©™æ±",
    "ç©ºè´§æ¶"
]

results = detector.detect(shelf_image, products)

# æ£€æŸ¥åº“å­˜
product_count = {}
for det in results:
    if det.class_name in product_count:
        product_count[det.class_name] += 1
    else:
        product_count[det.class_name] = 1
ç¤ºä¾‹ 3: äº¤é€šç›‘æ§Python# åˆ†æäº¤é€šçŠ¶å†µ
traffic_targets = [
    "çº¢ç¯",
    "ç»¿ç¯",
    "åœæ­¢çš„è½¦è¾†",
    "è¡Œé©¶ä¸­çš„è½¦è¾†",
    "äººè¡Œæ¨ªé“ä¸Šçš„è¡Œäºº"
]

results = detector.detect(traffic_cam, traffic_targets)

# æ£€æµ‹è¿è§„
for det in results:
    if det.class_name == "çº¢ç¯":
        red_light_box = det.bbox
        # æ£€æŸ¥é—¯çº¢ç¯çš„è½¦è¾†...
ç¤ºä¾‹ 4: è´¨é‡æ£€æŸ¥Python# æŸ¥æ‰¾äº§å“ç¼ºé™·
defect_targets = [
    "åˆ’ä¼¤çš„è¡¨é¢",
    "ç ´æŸçš„éƒ¨åˆ†",
    "å˜è‰²çš„åŒºåŸŸ",
    "ç¼ºå¤±çš„éƒ¨ä»¶"
]

results = detector.detect(product_image, defect_targets)

# è´¨é‡åˆ¤å®š
if len(results) > 0:
    print("æ£€æµ‹åˆ°ä¸è‰¯å“!")
    for det in results:
        print(f"é—®é¢˜: {det.class_name} at {det.bbox}")
else:
    print("æ­£å¸¸äº§å“")
ğŸ”§ åˆ©ç”¨ç»“æœæ•°æ®ä¿å­˜ä¸º JSONPython# å°†æ£€æµ‹ç»“æœä¿å­˜ä¸º JSON
import json

results = detector.detect(image, targets)
results_dict = detector.to_dict(results)

with open("detection_results.json", "w", encoding="utf-8") as f:
    json.dump(results_dict, f, indent=2, ensure_ascii=False)
ä¿å­˜åˆ°æ•°æ®åº“Python# å°†ç»“æœä¿å­˜åˆ°æ•°æ®åº“
for det in results:
    db.insert({
        "timestamp": datetime.now(),
        "object_type": det.class_name,
        "confidence": det.confidence,
        "location": det.bbox,
        "image_id": image_id
    })
å¯¼å‡ºä¸º CSVPythonimport csv

# å¯¼å‡ºä¸º CSV
with open("detections.csv", "w", newline='', encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["Class", "Confidence", "X1", "Y1", "X2", "Y2"])
    
    for det in results:
        writer.writerow([
            det.class_name,
            det.confidence,
            *det.bbox
        ])
âš¡ æ€§èƒ½ä¼˜åŒ–GPU åŠ é€ŸPython# æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
import torch
print(f"GPU æ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")

# åœ¨ GPU ä¸Šä½¿ç”¨ FP16 (é€Ÿåº¦å¿« 2 å€)
detector = DINOv3DetectorAPI(
    model_size="base",
    device="cuda",
    use_fp16=True  # é‡è¦!
)
å¤„ç†é€Ÿåº¦æ¯”è¾ƒæ¨¡å‹å¤§å°CPU (ç§’)GPU (ç§’)GPU+FP16 (ç§’)Small0.50.10.05Base1.00.20.1Large2.00.40.2å‡å°‘å†…å­˜ä½¿ç”¨Python# ä½¿ç”¨å°æ‰¹é‡è¿›è¡Œå¤„ç†
for i in range(0, len(images), 4):
    batch = images[i:i+4]
    results = detector.detect_batch(batch, targets)
    
# ä½¿ç”¨åæ¸…ç†å†…å­˜
import gc
del detector
torch.cuda.empty_cache()
gc.collect()
ğŸ†˜ é—®é¢˜æ’æŸ¥é¦–æ¬¡è¿è¡Œæ¨¡å‹ä¸‹è½½ç¼“æ…¢Python# è§£å†³æ–¹æ¡ˆ: æå‰ä¸‹è½½æ¨¡å‹
from transformers import AutoModel, AutoImageProcessor

# è¿è¡Œä¸€æ¬¡åå³ä¼šç¼“å­˜
AutoModel.from_pretrained("facebook/dinov3-vits16-pretrain-lvd1689m")
AutoImageProcessor.from_pretrained("facebook/dinov3-vits16-pretrain-lvd1689m")
CUDA out of memory é”™è¯¯Python# è§£å†³æ–¹æ¡ˆ 1: ä½¿ç”¨æ›´å°çš„æ¨¡å‹
detector = DINOv3DetectorAPI(model_size="small")

# è§£å†³æ–¹æ¡ˆ 2: å‡å°å›¾åƒå°ºå¯¸
image = cv2.resize(image, (640, 480))

# è§£å†³æ–¹æ¡ˆ 3: å‡å°æ‰¹é‡å¤§å°
results = detector.detect_batch(images[:2], targets)
æ£€æµ‹ç‡ä½Python# è§£å†³æ–¹æ¡ˆ 1: é™ä½é˜ˆå€¼
results = detector.detect(image, targets, confidence_threshold=0.1)

# è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨æ›´å…·ä½“çš„æè¿°
targets = ["å¤§çš„çº¢è‰²å¡è½¦", "å°çš„ç™½è‰²è½¿è½¦"]  # å¥½
# targets = ["è½¦"]  # å¤ªç¬¼ç»Ÿ

# è§£å†³æ–¹æ¡ˆ 3: ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
detector = DINOv3DetectorAPI(model_size="large")
ğŸ“Š ç»“æœç¤ºä¾‹æ£€æµ‹ç»“æœçš„æ ¼å¼å¦‚ä¸‹:PythonDetection(
    class_name="çº¢è‰²çš„è½¦",
    confidence=0.85,
    bbox=(120, 230, 450, 380)  # [x1, y1, x2, y2]
)
JSON è¾“å‡º:JSON{
    "class_name": "çº¢è‰²çš„è½¦",
    "confidence": 0.85,
    "bbox": [120, 230, 450, 380]
}
ğŸš€ å¼€å§‹ä½¿ç”¨ğŸ¯ ä½¿ç”¨æ–¹æ³•æ€»ç»“æ–¹å¼ 1: å‘½ä»¤è¡Œ (ç»ˆç«¯/CMD)Bash# æœ€ç®€å•çš„ç”¨æ³•
python detect.py å›¾åƒ.jpg "äºº" "æ±½è½¦"

# æŸ¥çœ‹å¸®åŠ©
python detect.py --help
æ–¹å¼ 2: GUI (æ¨èæ–°æ‰‹)Bashpython detect_gui.py
# ä½¿ç”¨é¼ æ ‡ç‚¹å‡»æ“ä½œ!
æ–¹å¼ 3: Python è„šæœ¬Pythonfrom production_api import DINOv3DetectorAPI

detector = DINOv3DetectorAPI()
results = detector.detect("image.jpg", ["person", "car"])
ğŸ“ å…¨éƒ¨æ–‡ä»¶è¯´æ˜æ–‡ä»¶ç”¨é€”é€‚ç”¨å¯¹è±¡detect.pyå‘½ä»¤è¡Œå•æ¬¡å¤„ç†ç»ˆç«¯ç”¨æˆ·detect_folder.pyæ–‡ä»¶å¤¹æ‰¹é‡å¤„ç†éœ€è¦æ‰¹é‡å¤„ç†æ—¶detect_gui.pyGUI ç•Œé¢æ–°æ‰‹, åå¥½é¼ æ ‡æ“ä½œproduction_api.pyPython APIå¼€å‘è€…test_simple.pyç®€å•æµ‹è¯•åˆæ¬¡ä½¿ç”¨æ—¶ğŸ’» è¿è¡Œç¤ºä¾‹åˆé›†Bash# 1. æµ‹è¯• (åˆæ¬¡ä½¿ç”¨æ—¶)
python test_simple.py

# 2. å•å¼ å›¾åƒ
python detect.py my_photo.jpg "äºº" "æ±½è½¦"

# 3. æ•´ä¸ªæ–‡ä»¶å¤¹
python detect_folder.py ./photos --targets "person,car" --output ./results

# 4. è¿è¡Œ GUI
python detect_gui.py

# 5. è§†é¢‘
python detect.py video.mp4 --targets "äºº" --output detected_video.mp4
ğŸ“ æ”¯æŒé—®é¢˜: æäº¤åˆ° GitHub Issuesæ”¹è¿›å»ºè®®: æ¬¢è¿ Pull Requestè®¸å¯è¯: MIT (å¯å•†ç”¨)ç°åœ¨å°±å¼€å§‹å§! åªéœ€å‡ è¡Œä»£ç ï¼Œå³å¯å®ç°å¼ºå¤§çš„ç›®æ ‡æ£€æµ‹ ğŸ¯
